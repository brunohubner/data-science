{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo ECLAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Função pronta para o algoritmo ECLAT (atualmente o algoritmo não está disponível em uma biblioteca)\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "from numpy import linalg as LA\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Global variable\n",
    "# containing all frequent patterns with its tid's\n",
    "F = []\n",
    "# Time calculation\n",
    "#start_time =0;\n",
    "# end_time=0;\n",
    "\n",
    "# Pattern class:\n",
    "\n",
    "\n",
    "class Pattern:\n",
    "    def __init__(self, item, tids):\n",
    "        # list of item Id's in the pattern\n",
    "        self.item_id = item\n",
    "        # tid of the pattern\n",
    "        self.tid_list = tids\n",
    "\n",
    "    # union operation of item Id's for two patterns to get ID of candidate pattern\n",
    "    def union_id(self, next_node):\n",
    "        t = set(self.item_id)\n",
    "        tt = set(next_node.item_id)\n",
    "        new = t | tt\n",
    "        new_id = list(new)\n",
    "        new_id.sort()\n",
    "        return new_id\n",
    "\n",
    "    # intersection of tid's of two patterns to find tid of candidate pattern\n",
    "    def intersec_tid_list(self, next_node):\n",
    "        t = set(self.tid_list)\n",
    "        tt = set(next_node.tid_list)\n",
    "        new = t & tt\n",
    "        new_list = list(new)\n",
    "        new_list.sort()\n",
    "        return new_list\n",
    "\n",
    "    # returns support value for the pattern\n",
    "    def getSup(self):\n",
    "        return len(self.tid_list)\n",
    "\n",
    "\n",
    "#\tdef\tcompare(self,n):\n",
    "#\t\tif self.item_id == n.item_id:\n",
    "#\t\t\treturn 1;\n",
    "#\t\treturn 0;\n",
    "\n",
    "    # Candidate generation & check for support\n",
    "\n",
    "    def generate_check(self, n, minsup):\n",
    "\n",
    "        # generating tid_list first\n",
    "        temp_tid_list = self.intersec_tid_list(n)\n",
    "\n",
    "        # if support for new candidate is >= minsup then only generate ID for that candidate\n",
    "        if len(temp_tid_list) >= minsup:\n",
    "            temp_id = self.union_id(n)\n",
    "            return (temp_id, temp_tid_list)\n",
    "        else:\n",
    "            return ([], [])\n",
    "\n",
    "    def pattern_print(self):\n",
    "        pattern_ID = str(\"\")\n",
    "        for i in self.item_id:\n",
    "            pattern_ID = pattern_ID + str(i) + ' '\n",
    "        print(pattern_ID + '\\t\\t : ' + str(self.tid_list))\n",
    "\n",
    "# End of Pattern class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Pattern Store class:\n",
    "class PatternStore:\n",
    "    def __init__(self):\n",
    "        self.Pattern_list = []\n",
    "\n",
    "    # Add a whole group of pattern to the list\n",
    "    def addGroup(self, list_nodes):\n",
    "        for n in list_nodes:\n",
    "            self.Pattern_list.append(n)\n",
    "\n",
    "    # Retursn i_th pattern from the list if available\n",
    "    def getNode(self, index):\n",
    "        if index < len(self.Pattern_list):\n",
    "            return self.Pattern_list[index]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    # To Fallow DFS method: Recursive function is used - to calculate all frequent patterns from the 1st level frequent list\n",
    "    def Eclat(self, minsup):\n",
    "        for node in self.Pattern_list:\n",
    "            F.append(node)\n",
    "            new_P = PatternStore()\n",
    "            # As all patterns are sorted initially get only next pattern from the current\n",
    "            index = self.Pattern_list.index(node)\n",
    "            i = index + 1\n",
    "            n = self.getNode(i)\n",
    "\n",
    "            while n:\n",
    "                # Here I am doing 2 steps togather: 1- candidate generation & 2- checking for minsup\n",
    "                (temp_id, temp_tid_list) = node.generate_check(n, minsup)\n",
    "                # if temp_id is not empty\n",
    "                if temp_id:\n",
    "                    new_P.Pattern_list.append(Pattern(temp_id, temp_tid_list))\n",
    "                i = i + 1\n",
    "                # get next node from the list\n",
    "                n = self.getNode(i)\n",
    "            # if any possible pattern child go to child first, DFS\n",
    "            if new_P.Pattern_list:\n",
    "                new_P.Eclat(minsup)\n",
    "\n",
    "# End of PatternStore class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class DBReader:\n",
    "\n",
    "    def __init__(self, filetoread):\n",
    "        self.file_id = filetoread\n",
    "\n",
    "    def readFile(self):\n",
    "        # stores each transaction\n",
    "        self.trans = []\n",
    "        # stores no of items in each tansaction\n",
    "        self.no_items = []\n",
    "        for line in self.file_id:\n",
    "            tuplex = line.split(\" \")\n",
    "            mylist = []\n",
    "            self.no_items.append(tuplex[0])\n",
    "            for position in range(1, len(tuplex)):\n",
    "                mylist.append(tuplex[position])\n",
    "\n",
    "            self.trans.append(mylist)\n",
    "\n",
    "    # From transactions: generate patterns and prepare a list\n",
    "    def genPatternList(self):\n",
    "        # all items\n",
    "        temp = [item for sublist in self.trans for item in sublist]\n",
    "\n",
    "        # removing duplicates\n",
    "        my_set = set(temp)\n",
    "        self.items = list(my_set)\n",
    "\n",
    "        # put in sorted oirder\n",
    "        self.items.sort()\n",
    "\n",
    "        # generate level_1 pattern list\n",
    "        self.level_1 = []\n",
    "\n",
    "        # Start the timmer as candidate generation for level 1 is a part of Eclat algorithm.\n",
    "        start_time = dt.datetime.now()\n",
    "\n",
    "        # generate all candidates for level 1\n",
    "        for it in self.items:\n",
    "            item = []\n",
    "            item.append(it)\n",
    "            self.level_1.append(Pattern(item, []))\n",
    "\n",
    "        # generate tid_list for every items in level 1\n",
    "        i = 0\n",
    "        for t in self.trans:\n",
    "            i = i + 1\n",
    "            t.sort()\n",
    "            for it_id in t:\n",
    "                index = self.items.index(it_id)\n",
    "                self.level_1[index].tid_list.append(i)\n",
    "\n",
    "        return start_time\n",
    "\n",
    "    # returns frequent patterns\n",
    "    def getFrequent(self, minsup):\n",
    "        self.P = []\n",
    "        for n in self.level_1:\n",
    "            c = int(n.getSup())\n",
    "            if c >= minsup:\n",
    "                # print c;\n",
    "                self.P.append(n)\n",
    "        return self.P\n",
    "\n",
    "# End of DBReader class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def main(file, support):\n",
    "    # printing flag\n",
    "    p_flag = 1\n",
    "\n",
    "    #parser = optparse.OptionParser(\"usage: %prog [options] arg1 arg2\")\n",
    "    #parser.add_option(\"-f\",  dest=\"filename\", default=\"data.txt\", type=\"string\", help=\"specify filename to run on\");\n",
    "    #parser.add_option(\"-s\",  dest=\"supnum\", default=0, type=\"int\", help=\"give minimun support to run on\");\n",
    "    #parser.add_option(\"-p\",  dest=\"p\", default=1, type=\"int\");\n",
    "    #(options, args) = parser.parse_args();\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-f\", \"--filename\")\n",
    "    parser.add_argument(\"-s\", \"--supnum\", type=int)\n",
    "    parser.add_argument(\"-p\", \"--print_flag\", action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # if\tlen(sys.argv) < 3:\n",
    "    #\tprint('Please give me the filename &  minimum support value'+os.linesep);\n",
    "    #\tsys.exit(1);\n",
    "    try:\n",
    "        # file name\n",
    "        f_name = file\n",
    "        fileToRead = open(f_name)\n",
    "        #fileToRead = open(\"data.txt\");\n",
    "        # Minimum Spport vlaue\n",
    "        minsup = support\n",
    "        # printing flag\n",
    "        if args.print_flag:\n",
    "            p_flag = 1\n",
    "    except(IOError, IndexError):\n",
    "        print('Bad file name'+os.linesep)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print('minsup = '+str(minsup))\n",
    "\n",
    "    #minsup = 2;\n",
    "\n",
    "    # DBReader object\n",
    "    reader = DBReader(fileToRead)\n",
    "    # reading the file\n",
    "    reader.readFile()\n",
    "    # Pattern generation for level 1 - It will return the starting time from when candidate generation is started.\n",
    "    start_time = reader.genPatternList()\n",
    "    # print\n",
    "\n",
    "    # Get frequent patterns from all candidates of level 1:\n",
    "    level1_P = reader.getFrequent(minsup)\n",
    "\n",
    "    # for n in level1_P:\n",
    "    #\tprint n.item_id;\n",
    "    #\tprint n.tid_list;\n",
    "\n",
    "    # correct\n",
    "\n",
    "    # Create Pattern Store object\n",
    "    PttStr = PatternStore()\n",
    "\n",
    "    # Add frequent patterns from level 1\n",
    "    PttStr.addGroup(level1_P)\n",
    "\n",
    "    # Eclat Algorithm\n",
    "    PttStr.Eclat(minsup)\n",
    "\n",
    "    end_time = dt.datetime.now()\n",
    "\n",
    "    # print start_time;\n",
    "    # print end_time;\n",
    "\n",
    "    time = end_time - start_time\n",
    "\n",
    "    print('Computation time = ' + str(time.total_seconds()) + ' Seconds')\n",
    "\n",
    "    if p_flag == 1:\n",
    "        print('Pattern\\t\\t : Tid_List')\n",
    "        for n in F:\n",
    "            n.pattern_print()\n",
    "\n",
    "# End of main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração dos itens frequentes\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"transacoes2.txt\", 3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cb3df648956af0506d640a215fefdce4a19a4b1e04258330e029d6b1a83406e"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
